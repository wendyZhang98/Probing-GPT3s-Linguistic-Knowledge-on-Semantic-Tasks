- Keywords: GPT-3, linguistics, probing
- Abstract: GPT-3 has attracted much attention from both academia and industry. However, it is still unclear what GPT-3 has understood or learned especially in linguistic knowledge. Some studies have shown linguistic phenomena including negation and tense are hard to be recognized by language models such as BERT. In this study, we conduct probing tasks focusing on semantic information. Specifically, we investigate GPT-3's linguistic knowledge on semantic tasks to identify tense, the number of subjects, and the number of objects for a given sentence. We also experiment with different prompt designs and temperatures of the decoding method. Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence. We also perform error analysis to summarize some common types of mistakes that GPT-3 has made when dealing with certain semantic information.

- We summarized our work in the paper named [<Probing GPT-3â€™s Linguistic Knowledge on Semantic Tasks>](https://aclanthology.org/2022.blackboxnlp-1.24/), which is accepted by [Blackbox NLP 2022 (Sponsored by Google)](https://blackboxnlp.github.io/).
